{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import os\n",
    "class SuperSimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperSimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=7, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Added BatchNorm2d and LeakyReLU to conv1 and conv2\n",
    "        self.batch_norm1 = nn.BatchNorm2d(16)\n",
    "        self.leaky_relu1 = nn.LeakyReLU(inplace=True)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm2d(32)\n",
    "        self.leaky_relu2 = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 4)  # Adjusted input size based on the output of the last convolutional layer\n",
    "        \n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu1(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.pool(x)  # Apply max pooling after the first convolutional layer\n",
    "\n",
    "        x = self.leaky_relu2(self.batch_norm2(self.conv2(x)))\n",
    "        x = self.pool(x)  # Apply max pooling after the second convolutional layer\n",
    "      \n",
    "        x = x.view(-1, 32 * 5 * 5)  # Adjusted input size for the fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_datasets(dataset):\n",
    "    # Split the dataset into training, test, and validation sets\n",
    "    train_data, test_val_data = train_test_split(dataset, test_size=0.30, random_state=42)\n",
    "    val_data,test_data = train_test_split(test_val_data, test_size=0.15, random_state=42)\n",
    "\n",
    "    return train_data, test_data, val_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_white_race(category):\n",
    "    return os.listdir(f'Assignment2/race/train/{category}/White')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_race(category):\n",
    "    return os.listdir(f'Assignment2/race/train/{category}/Black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_male(category,subcategory):\n",
    "    return os.listdir(f'Assignment2/{category}/train/{subcategory}/male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_female(category,subcategory):\n",
    "    return os.listdir(f'Assignment2/{category}/train/{subcategory}/female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "angry_male = get_file_male(\"gender\",\"angry\")\n",
    "angry_female=get_file_female(\"gender\",\"angry\")\n",
    "bored_male=get_file_male(\"gender\",\"bored\")\n",
    "bored_female=get_file_female(\"gender\",\"bored\")\n",
    "neutral_male=get_file_male(\"gender\",\"neutral\")\n",
    "neutral_female=get_file_female(\"gender\",\"neutral\")\n",
    "focused_female=get_file_female(\"gender\",\"focused\")\n",
    "focused_male=get_file_male(\"gender\",\"focused\")\n",
    "\n",
    "angry_white=get_white_race(\"angry\")\n",
    "angry_black=get_black_race(\"angry\")\n",
    "bored_white=get_white_race(\"bored\")\n",
    "bored_black=get_black_race(\"bored\")\n",
    "neutral_black=get_black_race(\"neutral\")\n",
    "neutral_white=get_white_race(\"neutral\")\n",
    "focused_black=get_black_race(\"focused\")\n",
    "focused_white=get_white_race(\"focused\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def get_image_label_pairs(folder_path, label, transform=None):\n",
    "    image_label_pairs = []\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):  # Filter by image extensions\n",
    "            image_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    # Resize the image to match the expected input size (e.g., 32x32)\n",
    "                    image = cv2.resize(image, (32, 32))\n",
    "\n",
    "                    # Convert to float and normalize\n",
    "                    image = image.astype(np.float32) / 255.0\n",
    "\n",
    "                    # Ensure the shape includes the channel dimension for PyTorch\n",
    "                    # Reshape the image to have a single channel (grayscale)\n",
    "                    image = image.reshape(1, 32, 32)\n",
    "\n",
    "                    # Convert the NumPy array to a PyTorch tensor\n",
    "                    image = torch.from_numpy(image)\n",
    "\n",
    "                    # Apply the specified transformations\n",
    "                    if transform:\n",
    "                        image = transform(image)\n",
    "\n",
    "                    image_label_pairs.append((image, label))\n",
    "                else:\n",
    "                    print(f\"Skipping {file} due to inability to read the image.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {file} due to error: {e}\")\n",
    "    return image_label_pairs\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert NumPy array to PIL Image\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally for data augmentation\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the pixel values to the range [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_male_data = get_image_label_pairs(\"Assignment2/gender/train/angry/male\", 0, transform=data_transform)\n",
    "angry_female_data = get_image_label_pairs(\"Assignment2/gender/train/angry/female\",0, transform=data_transform)\n",
    "\n",
    "angry_old_data = get_image_label_pairs(\"Assignment2/age/train/angry/old\", 0, transform=data_transform)\n",
    "angry_young_data = get_image_label_pairs(\"Assignment2/age/train/angry/young\",0, transform=data_transform)\n",
    "\n",
    "# angry_white_data = label_image_data(\"Assignment2/race/train/angry/white\", \"angry\", None,race=\"white\", transform=data_transform)\n",
    "# angry_black_data = label_image_data(\"Assignment2/race/train/angry/black\", \"angry\",None, race=\"black\", transform=data_transform)\n",
    "\n",
    "# Labeling for Bored\n",
    "bored_male_data = get_image_label_pairs(\"Assignment2/gender/train/bored/male\", 1, transform=data_transform)\n",
    "bored_female_data = get_image_label_pairs(\"Assignment2/gender/train/bored/female\",1, transform=data_transform)\n",
    "\n",
    "bored_old_data = get_image_label_pairs(\"Assignment2/age/train/bored/old\", 1, transform=data_transform)\n",
    "bored_young_data = get_image_label_pairs(\"Assignment2/age/train/bored/young\",1, transform=data_transform)\n",
    "\n",
    "# Add race information if available\n",
    "# bored_white_data = label_image_data(\"Assignment2/race/train/bored/white\", \"bored\",None, \"white\", transform=data_transform)\n",
    "# bored_black_data = label_image_data(\"Assignment2/race/train/bored/black\", \"bored\",None, \"black\", transform=data_transform)\n",
    "\n",
    "# Labeling for Neutral\n",
    "neutral_male_data = get_image_label_pairs(\"Assignment2/gender/train/neutral/male\", 3, transform=data_transform)\n",
    "neutral_female_data = get_image_label_pairs(\"Assignment2/gender/train/neutral/female\",3, transform=data_transform)\n",
    "\n",
    "neutral_old_data = get_image_label_pairs(\"Assignment2/age/train/neutral/old\", 3, transform=data_transform)\n",
    "neutral_young_data = get_image_label_pairs(\"Assignment2/age/train/neutral/young\",3, transform=data_transform)\n",
    "\n",
    "# Add race information if available\n",
    "# neutral_white_data = label_image_data(\"Assignment2/race/train/neutral/white\", \"neutral\",None, \"white\", transform=data_transform)\n",
    "# neutral_black_data = label_image_data(\"Assignment2/race/train/neutral/black\", \"neutral\",None, \"black\", transform=data_transform)\n",
    "\n",
    "# Labeling for Focused\n",
    "focused_male_data = get_image_label_pairs(\"Assignment2/gender/train/focused/male\", 2, transform=data_transform)\n",
    "focused_female_data = get_image_label_pairs(\"Assignment2/gender/train/focused/female\",2, transform=data_transform)\n",
    "\n",
    "focused_old_data = get_image_label_pairs(\"Assignment2/age/train/focused/old\", 2, transform=data_transform)\n",
    "focused_young_data = get_image_label_pairs(\"Assignment2/age/train/focused/young\",2, transform=data_transform)\n",
    "\n",
    "# Add race information if available\n",
    "# focused_white_data = label_image_data(\"Assignment2/race/train/focused/white\", \"focused\",None, \"white\", transform=data_transform)\n",
    "# focused_black_data = label_image_data(\"Assignment2/race/train/focused/black\", \"focused\",None, \"black\", transform=data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "female_image=focused_female_data+angry_female_data+bored_female_data+neutral_female_data\n",
    "male_image=focused_male_data+angry_male_data+bored_male_data+neutral_male_data\n",
    "\n",
    "\n",
    "young_images=focused_young_data+bored_young_data+neutral_young_data+angry_young_data\n",
    "old_images=focused_old_data+bored_old_data+neutral_old_data+angry_old_data\n",
    "\n",
    "batch_size = 32  # Set your desired batch size\n",
    "custome_female=CustomDataset(female_image)\n",
    "custome_female_loader =DataLoader(female_image, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "batch_size = 32  # Set your desired batch size\n",
    "custome_male=CustomDataset(male_image)\n",
    "custome_male_loader =DataLoader(male_image, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size = 32  # Set your desired batch size\n",
    "custome_young=CustomDataset(young_images)\n",
    "custome_young_loader =DataLoader(young_images, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size = 32  # Set your desired batch size\n",
    "custome_old=CustomDataset(old_images)\n",
    "custome_old_loader =DataLoader(old_images, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperSimpleCNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (batch_norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (leaky_relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (leaky_relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  (fc1): Linear(in_features=800, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SuperSimpleCNN()\n",
    "model.load_state_dict(torch.load('Best_model.pth'))\n",
    "# pretrained = all(key.startswith('features') or key.startswith('classifier') for key in model.state_dict().keys())\n",
    "\n",
    "# if pretrained:\n",
    "#     print(\"The model is pretrained.\")\n",
    "# else:\n",
    "#     print(\"The model is not pretrained.\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def get_confusion_matrix(model, custom_testing_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in custom_testing_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    # Display or print the confusion matrix\n",
    "    # print(\"Confusion Matrix:\")\n",
    "   \n",
    "    class_labels = ['angry', 'bored', 'focused', 'neutral']\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"\\t\\t\" + \"\\t\".join(class_labels))\n",
    "    for i, row in enumerate(cm):\n",
    "        print(f\"{class_labels[i]}\\t\" + \"\\t\\t\".join(map(str, row)))\n",
    "\n",
    "    \n",
    "    if class_labels:\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(all_labels, all_predictions, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\t\tangry\tbored\tfocused\tneutral\n",
      "angry\t128\t\t19\t\t18\t\t45\n",
      "bored\t25\t\t176\t\t22\t\t88\n",
      "focused\t5\t\t6\t\t165\t\t31\n",
      "neutral\t15\t\t32\t\t24\t\t214\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.74      0.61      0.67       210\n",
      "       bored       0.76      0.57      0.65       311\n",
      "     focused       0.72      0.80      0.76       207\n",
      "     neutral       0.57      0.75      0.65       285\n",
      "\n",
      "    accuracy                           0.67      1013\n",
      "   macro avg       0.70      0.68      0.68      1013\n",
      "weighted avg       0.69      0.67      0.67      1013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_confusion_matrix(model,custom_testing_loader=custome_female_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\t\tangry\tbored\tfocused\tneutral\n",
      "angry\t239\t\t54\t\t33\t\t77\n",
      "bored\t44\t\t138\t\t33\t\t47\n",
      "focused\t15\t\t22\t\t441\t\t44\n",
      "neutral\t34\t\t24\t\t49\t\t245\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.72      0.59      0.65       403\n",
      "       bored       0.58      0.53      0.55       262\n",
      "     focused       0.79      0.84      0.82       522\n",
      "     neutral       0.59      0.70      0.64       352\n",
      "\n",
      "    accuracy                           0.69      1539\n",
      "   macro avg       0.67      0.67      0.67      1539\n",
      "weighted avg       0.69      0.69      0.69      1539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_confusion_matrix(model,custom_testing_loader=custome_male_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\t\tangry\tbored\tfocused\tneutral\n",
      "angry\t221\t\t40\t\t30\t\t59\n",
      "bored\t33\t\t135\t\t26\t\t41\n",
      "focused\t14\t\t9\t\t241\t\t20\n",
      "neutral\t23\t\t16\t\t41\t\t187\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.76      0.63      0.69       350\n",
      "       bored       0.68      0.57      0.62       235\n",
      "     focused       0.71      0.85      0.77       284\n",
      "     neutral       0.61      0.70      0.65       267\n",
      "\n",
      "    accuracy                           0.69      1136\n",
      "   macro avg       0.69      0.69      0.68      1136\n",
      "weighted avg       0.70      0.69      0.69      1136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_confusion_matrix(model,custom_testing_loader=custome_old_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\t\tangry\tbored\tfocused\tneutral\n",
      "angry\t172\t\t27\t\t29\t\t61\n",
      "bored\t29\t\t161\t\t22\t\t64\n",
      "focused\t12\t\t16\t\t381\t\t65\n",
      "neutral\t35\t\t61\t\t49\t\t388\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.69      0.60      0.64       289\n",
      "       bored       0.61      0.58      0.60       276\n",
      "     focused       0.79      0.80      0.80       474\n",
      "     neutral       0.67      0.73      0.70       533\n",
      "\n",
      "    accuracy                           0.70      1572\n",
      "   macro avg       0.69      0.68      0.68      1572\n",
      "weighted avg       0.70      0.70      0.70      1572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_confusion_matrix(model,custom_testing_loader=custome_young_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
